# Project: A Simplified Implementation of FlashAttention in CUDA

This is the repository for my senior design project, focusing on a
high-performance implementation of a memory-aware attention mechanism for
Transformer models.

This is the repository for my senior design project, focusing on a
high-performance implementation of a memory-aware attention mechanism for
Transformer models.
